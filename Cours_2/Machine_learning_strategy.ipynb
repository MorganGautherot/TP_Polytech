{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MorganGautherot/Machine_Learning_Courses/blob/master/Lecture_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "1elEzKC_gw9L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Strategy\n",
        "*Author -- Morgan Gautherot*\n",
        "\n",
        "If you have any question please feel free to send me an email at :\n",
        "\n",
        "gautherotmorgan0@gmail.com"
      ]
    },
    {
      "metadata": {
        "id": "H9i7Z4eZifDk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1 Feature scaling"
      ]
    },
    {
      "metadata": {
        "id": "seuiWx3eikEq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Feature scaling is very important step before modeling, it avoid gradient descent to diverge, and even helps it to converge quickly."
      ]
    },
    {
      "metadata": {
        "id": "Uw9QyE6PkNwv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mUnh6KDdjyv2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's import 'multivariate_regression.txt'"
      ]
    },
    {
      "metadata": {
        "id": "dQ3p4G10ijAt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xYKl04qes47C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We take again our data set with two features, square meters and number of rooms in order to predict the price of houses."
      ]
    },
    {
      "metadata": {
        "id": "h5Bwlr09kH1O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# upload the dataset\n",
        "multivariate_regression = np.genfromtxt('multivariate_regression.txt', delimiter=',')\n",
        "\n",
        "m, _ = multivariate_regression.shape\n",
        "\n",
        "#X = np.stack(multivariate_regression[:, :2], axis=1)\n",
        "X = multivariate_regression[:, :2] \n",
        "Y = multivariate_regression[:, 2].reshape((1, m))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nnCxOBj1uFb-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will use function implemented in the previous exercice."
      ]
    },
    {
      "metadata": {
        "id": "Gtr6MTL5kP8g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(X, W):\n",
        "  \"\"\" Predict our h(x) in function of their features \n",
        "  INPUT :\n",
        "    X shape(n, m)\n",
        "    W shape(n, 1)\n",
        "  OUTPUT :\n",
        "    h shape(1, m)\"\"\"\n",
        "\n",
        "  return np.dot(W.T, X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "It7j2YYulQbZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ComputeCost(X, W, Y):\n",
        "  \"\"\" Compute cost for linear regression \n",
        "  INPUT :\n",
        "    X shape(n, m)\n",
        "    W shape(n, 1)\n",
        "    Y shape(1, m)\n",
        "  OUTPUT :\n",
        "    J float\"\"\"\n",
        "\n",
        "  _, m = X.shape\n",
        "\n",
        "  return 1/(2*m) * np.dot((predict(X, W)-Y), (predict(X, W)-Y).T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4GruKagYtRrA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We change a bit 'gradientDescent' in order to output w history."
      ]
    },
    {
      "metadata": {
        "id": "M9C2AoIsl6LM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gradientDescent(X, W, Y, alpha, num_iters):\n",
        "  \"\"\" gradientDescent compute gradient descent to learn best W\n",
        "  INPUT :\n",
        "    X           shape(n, m)\n",
        "    W           shape(n, 1)\n",
        "    Y           shape(1, m)\n",
        "    alpha       float\n",
        "    num_iters   integer\n",
        "  OUTPUT :\n",
        "    W           shape(n, 1)\n",
        "    J_history   shape(num_iters,)\n",
        "    W_history.  len(num_iters)\"\"\"\n",
        "  \n",
        "  _, m = X.shape\n",
        "  J_history = np.zeros(num_iters)\n",
        "  W_history = []\n",
        "  \n",
        "  for it in range(0, num_iters):\n",
        "\n",
        "    gradient = (alpha/m) * np.dot(X, (predict(X, W)-Y).T)\n",
        "    W = W - gradient\n",
        "    \n",
        "    J_history[it] = ComputeCost(X, W, Y)\n",
        "    W_history.append(W)\n",
        "    \n",
        "  return W, J_history, W_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wugnoWfRmGMo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lr_fit(X, W, Y, alpha, num_iters) :\n",
        "  \"\"\" lr_fit train our algorithm to find the best W for our prediction\n",
        "  INPUT :\n",
        "    X          shape(m, n-1)\n",
        "    W          shape(n, 1)\n",
        "    Y          shape(1, m)\n",
        "    alpha      float\n",
        "    num_iters  integer\n",
        "  OUPUT :\n",
        "    W          shape(n, 1)\n",
        "    J_history  shape(num_iters,)\n",
        "    W_history  len(num_iters)\"\"\"\n",
        "  \n",
        "  m, _ = X.shape\n",
        "  \n",
        "  X_1 = np.stack(np.hstack((np.ones(m).reshape(m, 1), X)), axis=1)\n",
        "  \n",
        "  W, J_history, W_history = gradientDescent(X_1, W, Y, alpha, num_iters)\n",
        "  \n",
        "  return W, J_history, W_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yWzvGFLgmSD1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alpha = 0.01\n",
        "num_iters = 200\n",
        "W = np.array([0, 0, 0]).reshape(3, 1)\n",
        "W, J_history, W_history = lr_fit(X, W, Y, alpha, num_iters)\n",
        "print(W)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FVNV6jubm8_X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We obtain 'nan' value which in python mean 'Not A Number'.\n",
        "\n",
        "But why do we get 'nan' value.\n",
        "\n",
        "Take a look at J_history."
      ]
    },
    {
      "metadata": {
        "id": "Ze4qJhIqrMh5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(J_history)\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"J(W)\")\n",
        "plt.title(\"Minimization of the cost function after each iterations\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Os06WBPArybj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(J_history[:76])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bt7zS3tEoIKa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As you can see, number become too great and computer can not support them anymore."
      ]
    },
    {
      "metadata": {
        "id": "xLYIv_i7n2Jm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for w in W_history[:10]:\n",
        "  print('w0: '+str(np.squeeze(w[0]))+', w1: '+str(np.squeeze(w[1]))+', w2:'+str(np.squeeze(w[2])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TaTF_UBxsPwF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Take a look at our data:\n",
        "\n",
        "$X_1$ is the square meter of our house\n",
        "\n",
        "$X_2$ is the number of rooms"
      ]
    },
    {
      "metadata": {
        "id": "SOVHx_wynxgX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(X[:10, :])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uowi5bDlwDmq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('x1 mean: '+str(np.mean(X[:, 0])))\n",
        "print('x1 std: '+str(np.std(X[:, 0])))\n",
        "print('x2 mean: '+str(np.mean(X[:, 1])))\n",
        "print('x2 std: '+str(np.std(X[:, 1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8DtDlpsFth23",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$X_1$ is quite large and it is the cause of our problem."
      ]
    },
    {
      "metadata": {
        "id": "fYFul7NjuPBn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Standardization from scratch\n",
        "\n",
        "It's your turn, implement a function which can normalize data:\n",
        "$$ x'=\\frac{x-\\bar{x}}{\\sigma}$$\n",
        "\n",
        "Tips : read the documentation for np.mean() and np.std()"
      ]
    },
    {
      "metadata": {
        "id": "qWscmUsGt-8x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def standardization(X):\n",
        "  \"\"\"standardization take a data set \n",
        "  substract their observations by their mean\n",
        "  and divide them by their standard deviation\n",
        "  INPUT:\n",
        "    X          shape(m, n-1)\n",
        "  OUPUT:\n",
        "    X          shape(m, n-1)\n",
        "    mean_X.    shape(2,)\n",
        "    std_X.     shape(2,)\"\"\"\n",
        "  \n",
        "### Your code start here ###\n",
        "  return \n",
        "### Your code end here ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ubq2dRMlvvUe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "standardize_X, mean_X, std_X = standardization(X)\n",
        "\n",
        "print('x1 mean: '+str(mean_X[0]))\n",
        "print('x1 std: '+str(std_X[0]))\n",
        "print('x2 mean: '+str(mean_X[1]))\n",
        "print('x2 std: '+str(std_X[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GESF0ay8uOlF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Expected values : \n",
        "\n",
        "x1 mean: 2000\n",
        "\n",
        "x1 std: 786\n",
        "\n",
        "x2 mean: 3.1\n",
        "\n",
        "x2 std: 0.75"
      ]
    },
    {
      "metadata": {
        "id": "YtaShUQ1zDB9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can try to train a model with our new data."
      ]
    },
    {
      "metadata": {
        "id": "IGMQtCkgzCVt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alpha = 0.01\n",
        "num_iters = 200\n",
        "W = np.array([0, 0, 0]).reshape(3, 1)\n",
        "W, J_history, W_history = lr_fit(standardize_X, W, Y, alpha, num_iters)\n",
        "print(W)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PpoDY0QVzSoG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have good value for W."
      ]
    },
    {
      "metadata": {
        "id": "52bHYt9HzQp9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(J_history)\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"J(W)\")\n",
        "plt.title(\"Minimization of the cost function after each iterations\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B6CVeu5OzW5r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our train converge to a minimum global."
      ]
    },
    {
      "metadata": {
        "id": "wMYZokye19O9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Standardization using sklearn"
      ]
    },
    {
      "metadata": {
        "id": "4P8vbhra2jZT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import StandardScaler from sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the function\n",
        "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "\n",
        "# Compute mean and standard deviation\n",
        "scaler.fit(X)\n",
        "\n",
        "# see the mean and the std\n",
        "print('Mean for X1 and X2: '+str(scaler.mean_))\n",
        "print('\\nStandard deviation for X1 and X2: '+str(scaler.var_))\n",
        "\n",
        "new_X = scaler.transform(X)\n",
        "print('\\nFirst 10 rows of our data set standardize:')\n",
        "print(new_X[:10, :])\n",
        "\n",
        "initial_X = scaler.inverse_transform(new_X)\n",
        "print('\\nTransform our standardize data in the initial scale:')\n",
        "print(initial_X[:10, :])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "asZS8KGxI-UT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2 Regression metrics"
      ]
    },
    {
      "metadata": {
        "id": "vErgc4v1JMYq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this part you will learn more about performance metrics for regression"
      ]
    },
    {
      "metadata": {
        "id": "kPAjdlrfJUgl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Root Mean Square Error (RMSE)"
      ]
    },
    {
      "metadata": {
        "id": "SWVecwdfJZGm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You will implement a function which compute RMSE as a performance metrics:\n",
        "$$\\sqrt{\\frac{1}{N}\\sum^{N}_{i=1}(y_i-\\hat{y}_i)^2}$$"
      ]
    },
    {
      "metadata": {
        "id": "5ExelUZYNYsS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def root_mean_square_error(y_predict, y_true):\n",
        "  \"\"\"compute root square error for \n",
        "  y_predict with respect to y_true\n",
        "  INPUT:\n",
        "    y_predict  shape(1, m)\n",
        "    y_true.    shape(1, m)\n",
        "  OUPUT:\n",
        "    RMSE.      constant\"\"\"\n",
        "  \n",
        "  _, m = y_true.shape\n",
        "  \n",
        "### Your code start here ###\n",
        "  return \n",
        "### Your code end here ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GF8TyPJxOjMr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "standardize_X_1 = np.stack(np.hstack((np.ones(m).reshape(m, 1), standardize_X)), axis=1)\n",
        "\n",
        "y_predict = predict(standardize_X_1, W)\n",
        "\n",
        "RMSE = root_mean_square_error(y_predict, Y)\n",
        "\n",
        "print('Root Mean Square Error: '+str(RMSE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g9X8b907RZd4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Expected values : \n",
        "\n",
        "Root Mean Square Error: 81789.61"
      ]
    },
    {
      "metadata": {
        "id": "whlVpJ1XSDdd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RMSE with sklearn"
      ]
    },
    {
      "metadata": {
        "id": "Fwne4mTiSHGY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "sklearn doesn't implemented RMSE, if we want to use RMSE we just have to apply np.sqrt to MSE."
      ]
    },
    {
      "metadata": {
        "id": "tzS_1W8yRY4x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def root_mean_square_error_sklearn(y_predict, y_true):\n",
        "  \"\"\"compute root square error for \n",
        "  y_predict with respect to y_true using sklearn\n",
        "  INPUT:\n",
        "    y_predict  shape(1, m)\n",
        "    y_true.    shape(1, m)\n",
        "  OUPUT:\n",
        "    RMSE.      constant\"\"\"\n",
        "  \n",
        "  return np.sqrt(mean_squared_error(y_predict, Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ywb63p9-RBOa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RMSE = root_mean_square_error_sklearn(y_predict, Y)\n",
        "\n",
        "print('Root Mean Square Error: '+str(RMSE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0A3UreYdLhCz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### R-squared"
      ]
    },
    {
      "metadata": {
        "id": "u2tMpFsELkmU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You will implement a function which compute R-squared as a performance metrics:\n",
        "$$1-\\frac{\\frac{1}{N}\\sum^{N}_{i=1}(y_i-\\hat{y}_i)^2}{\\frac{1}{N}\\sum^{N}_{i=1}(y_i-\\bar{y}_i)^2}$$"
      ]
    },
    {
      "metadata": {
        "id": "6GpR7c4-NZTL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def R_squared(y_predict, y_true):\n",
        "  \"\"\"compute R squared for \n",
        "  y_predict with respect to y_true\n",
        "  INPUT:\n",
        "    y_predict  shape(1, m)\n",
        "    y_true     shape(1, m)\n",
        "  OUPUT:\n",
        "    R-squared  constant\"\"\"\n",
        "  \n",
        "  _, m = y_true.shape\n",
        "  \n",
        "### Your code start here ###\n",
        "  return \n",
        "### Your code end here ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BZseluPvTnm-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "R2 = R_squared(y_predict, Y)\n",
        "\n",
        "print('Root Mean Square Error: '+str(R2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i5XzgXVgUr8-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Expected values :\n",
        "R_squared: 0.56"
      ]
    },
    {
      "metadata": {
        "id": "79dk2GGCVV4I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### R-squared with sklearn"
      ]
    },
    {
      "metadata": {
        "id": "YSBVITxO6Ksd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "R2 = r2_score(np.squeeze(Y), np.squeeze(y_predict))\n",
        "\n",
        "print('Root Mean Square Error: '+str(R2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1tng8KhcVkqt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3 Classification metrics"
      ]
    },
    {
      "metadata": {
        "id": "zTGb2iwhWXop",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this part you will learn more about performance metrics for regression"
      ]
    },
    {
      "metadata": {
        "id": "PCWPzI8sWYar",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Accuracy score from scratch"
      ]
    },
    {
      "metadata": {
        "id": "9NYy8UIFWcvR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You have to implement Accuracy score:\n",
        "$$\\frac{1}{N}\\sum^{N}_{i=1}[\\hat{y}_i=y_i]$$"
      ]
    },
    {
      "metadata": {
        "id": "0AGomwXzXFbg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy_score(y_predict, y_true):\n",
        "  \"\"\"compute accuracy score for \n",
        "  y_predict with respect to y_true\n",
        "  INPUT:\n",
        "    y_predict  shape(1, m)\n",
        "    y_true     shape(1, m)\n",
        "  OUPUT:\n",
        "    accuracy   constant\"\"\"\n",
        "  \n",
        "  m = len(y_true)\n",
        "  \n",
        "  ### Your code start here ###\n",
        "  return \n",
        "  ### Your code end here ###\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxreykdYWcDa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_predict = np.zeros(100)\n",
        "y_true = np.hstack((np.zeros(25),np.ones(25),np.zeros(25),np.ones(25)))\n",
        "\n",
        "accuracy = accuracy_score(y_predict, y_true)\n",
        "\n",
        "print(\"Accuracy score: \"+str(accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "38VJ29SuYZF7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Expected values :\n",
        "\n",
        "Accuracy score: 0.5"
      ]
    },
    {
      "metadata": {
        "id": "nGaJB5EyZjfH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now you want to predict rare events you can have 1% in one class and 99% in the other class. "
      ]
    },
    {
      "metadata": {
        "id": "w6juoiRAaID9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_true = np.hstack((np.zeros(990),np.ones(10)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lt5BrST8aS-f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Imagine you have a very poor model which predict all your data at 0."
      ]
    },
    {
      "metadata": {
        "id": "RpN8BOeVXDUZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_predict = np.zeros(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wMq5Kfhiaqei",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Try to use accuracy score to measure the parformance of your model."
      ]
    },
    {
      "metadata": {
        "id": "lStyZkuaa006",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "accuracy_score(y_predict, y_true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rRaI9S_ebbAD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "if you just see the performance and not the prediction you can think that your model is very good whereas it has not understand how to predict your data.\n",
        "\n",
        "Accuracy score can be meaningful when your dataset is balanced."
      ]
    },
    {
      "metadata": {
        "id": "DuJ-tB2gb9Fi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Accuracy score from sklearn"
      ]
    },
    {
      "metadata": {
        "id": "uI3DQbFPbqOT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_predict = np.zeros(100)\n",
        "y_true = np.hstack((np.zeros(25),np.ones(25),np.zeros(25),np.ones(25)))\n",
        "\n",
        "accuracy = accuracy_score(y_predict, y_true)\n",
        "\n",
        "print(\"Accuracy score: \"+str(accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EAzONAnOdxT4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cross-entropy loss or log loss from scratch"
      ]
    },
    {
      "metadata": {
        "id": "i12MCZo3izJf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's generate two distributions."
      ]
    },
    {
      "metadata": {
        "id": "SDPqn6Bhiwo7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_11 = 1 * np.random.randn(100) + 0\n",
        "x_21 = 2 * np.random.randn(100) + 2\n",
        "x_12 = 1 * np.random.randn(100) + 0\n",
        "x_22 = 2 * np.random.randn(100) + 7\n",
        "\n",
        "x_1 = np.concatenate((x_11, x_12))\n",
        "x_2 = np.concatenate((x_21, x_22))\n",
        "X = np.stack((x_1, x_2), axis=-1)\n",
        "\n",
        "Y = np.concatenate((np.repeat(0, 100), np.repeat(1, 100)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IBtHJd39i6hq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Take the previous TP as an example and use sklearn to create a model with X and Y"
      ]
    },
    {
      "metadata": {
        "id": "T7u1mBCki5sX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "\n",
        "log_reg = LogisticRegression(solver='lbfgs', random_state=123)\n",
        "### Your code start here ###\n",
        "\n",
        "# train the model\n",
        "\n",
        "\n",
        "# Do not take the predict but the probability to belong to class 1\n",
        "y_predict = \n",
        "\n",
        "### Your code end here ###\n",
        "\n",
        "w_0 = np.squeeze(log_reg.intercept_)\n",
        "w_1, w_2 = np.squeeze(log_reg.coef_)\n",
        "print(\"w_0 : \"+str(w_0)+\"\\nw_1 : \"+str(w_1)+\"\\nw_2 : \"+str(w_2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V--hllFLjPcC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Expected values :\n",
        "\n",
        "w_0 : -6.18\n",
        "\n",
        "w_1 : -0.35\n",
        "\n",
        "w_2 : 1.40\n",
        "\n",
        "y_predict : shape(200,)"
      ]
    },
    {
      "metadata": {
        "id": "iDSCXUbfjGQU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = np.array(range(-3, 4))\n",
        "y = (-1/w_2) * (x * w_1 + w_0)\n",
        "\n",
        "plt.plot(x, y, c='red')\n",
        "\n",
        "plt.scatter(x_11, x_21, c = 'blue')\n",
        "plt.scatter(x_12, x_22, c = 'orange')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N018aQEqea1Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You have to implement cross-entropy from scratch:\n",
        "$$ -\\frac{1}{N}\\sum^{N}_{i=1}y_i \\log{(\\hat{y}_i)}+(1-y_i)\\log{(1-\\hat{y}_i)}$$"
      ]
    },
    {
      "metadata": {
        "id": "wlZj5YiUd6Tx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log_loss_scratch(y_predict, y_true):\n",
        "  \"\"\"compute accuracy score for \n",
        "  y_predict with respect to y_true\n",
        "  INPUT:\n",
        "    y_predict  shape(1, m)\n",
        "    y_true     shape(1, m)\n",
        "  OUPUT:\n",
        "    log_loss   constant\"\"\"\n",
        "  \n",
        "  m = len(y_true)\n",
        "  \n",
        "  ### Your code start here ###\n",
        "  return \n",
        "  ### Your code end here ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jk_gXXBcXo7V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log_loss = log_loss_scratch(y_predict, Y)\n",
        "\n",
        "print(\"Accuracy score: \"+str(log_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EkODfIUSlVCi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Expected values :\n",
        "\n",
        "Accuracy score: 0.22"
      ]
    },
    {
      "metadata": {
        "id": "8svLQ_xjlitH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cross entropy log loss from sklean"
      ]
    },
    {
      "metadata": {
        "id": "NRT9db2wbIP2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "log_loss = log_loss(Y, y_predict)\n",
        "\n",
        "print(\"Accuracy score: \"+str(log_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j2VzSHF62dq-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Precision, Recall et $F_1$ score"
      ]
    },
    {
      "metadata": {
        "id": "01wXW8Wd2f5_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It's not worth to implement confusion matrix, precision and recall but you will use the sklearn implementation."
      ]
    },
    {
      "metadata": {
        "id": "UecVFhxJ6VM8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Transform soft prediction y_predict into hard prediction y_predict_hard"
      ]
    },
    {
      "metadata": {
        "id": "C4jJ8obLAXwP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def threshold(y_predict, thresh):\n",
        "    \"\"\"compute accuracy score for \n",
        "  y_predict with respect to y_true\n",
        "  INPUT:\n",
        "    y_predict      shape(1, m)\n",
        "    tresh          constant\n",
        "  OUPUT:\n",
        "    y_predict_hard shape(1,m)\"\"\"\n",
        "    \n",
        "### Your code start here ###\n",
        "    return \n",
        "### Your code end here ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xwecWSEihMrn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "y_predict_hard = threshold(y_predict, 0.5)\n",
        "\n",
        "\n",
        "print('Number observation predict belong to class 1: '+str(sum(y_predict_hard)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I3ukT3n77MeR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Expected result:\n",
        "\n",
        "Number observation predict belong to class 1: 102"
      ]
    },
    {
      "metadata": {
        "id": "wD-mUYONh1oj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(Y, y_predict_hard))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HzIcVDPi8mRv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Complete with numbers above:\n",
        "\n",
        "TN =\n",
        "\n",
        "FP = \n",
        "\n",
        "FN = \n",
        "\n",
        "TP = "
      ]
    },
    {
      "metadata": {
        "id": "jO2xqUSd9eTs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$$ Precision=\\frac{TP}{TP+FP}$$"
      ]
    },
    {
      "metadata": {
        "id": "aOcFSVYz7xZ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision = precision_score(Y, y_predict_hard)\n",
        "\n",
        "print('Preicsion score: '+str(precision))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j8GbnuHD-l-n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$$ Recall=\\frac{TP}{TP+FN}$$\n"
      ]
    },
    {
      "metadata": {
        "id": "mqdYHzAG-Sw0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "recall = recall_score(Y, y_predict_hard)\n",
        "\n",
        "print('Recall score: '+str(recall))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eOMGOuAm-m07",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$$ F_1 score=2.\\frac{Precision.Recall}{Precision+Recall}$$"
      ]
    },
    {
      "metadata": {
        "id": "kdaGWl92-YRc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1 = f1_score(Y, y_predict_hard)\n",
        "\n",
        "print('F1 score: '+str(f1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UzjFFLxe_euZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We plot a curve to help use find the best threshold in function of precision and recall"
      ]
    },
    {
      "metadata": {
        "id": "F0myxWol_Uib",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "thresh = np.arange(0, 1, 0.01)\n",
        "recall = np.zeros(100)\n",
        "precision = np.zeros(100)\n",
        "f1 = np.zeros(100)\n",
        "\n",
        "for i in range(0, 100):\n",
        "  \n",
        "\n",
        "  recall[i] = recall_score(Y, threshold(y_predict, thresh[i]))\n",
        "  precision[i] = precision_score(Y, threshold(y_predict, thresh[i]))\n",
        "  f1[i] = f1_score(Y, threshold(y_predict, thresh[i]))\n",
        "  \n",
        "plt.plot(thresh, precision, label='precision')\n",
        "plt.plot(thresh, recall, label='recall')\n",
        "plt.plot(thresh, f1, label='f1', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('Percentage')\n",
        "plt.title('Precision, Recall and f1 score in function of threshold', fontsize=17)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "deOIlAPlEiiY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this example we can take threshold that make the best compromise between precision and recall."
      ]
    },
    {
      "metadata": {
        "id": "-UlBizu7Eqwx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index = np.argmax(f1)\n",
        "\n",
        "print('Threshold which maximize f1 score is: '+str(thresh[index]))\n",
        "print('F1 score: '+str(f1[index]))\n",
        "print('Precision: '+str(precision[index]))\n",
        "print('Recall: '+str(recall[index]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BimIzjVbFM_l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can interpret this precision like, 87% of obversations that our model classified as 1 is really 1.\n",
        "\n",
        "We can interpret this recall like, 97% of observations that are really 1 are detected. "
      ]
    },
    {
      "metadata": {
        "id": "0aj67MAkHaxt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### AUC and ROC Curve"
      ]
    },
    {
      "metadata": {
        "id": "moXWchGbHqSy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It's not worth to implement AUC and ROC Curve we will use sklearn instead.\n",
        "\n",
        "AUC doesn't need hard prediction to be effective."
      ]
    },
    {
      "metadata": {
        "id": "XAuCfThwCNmJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc_score(Y, y_predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mdTKppafIql5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(Y, y_predict, pos_label=None, sample_weight=None, drop_intermediate=True)\n",
        "\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False positive rate (1-specificity)')\n",
        "plt.ylabel('True positive rate (sensitivity)')\n",
        "plt.title('ROC Curve', fontsize=17)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wazoLuCAKrBE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4 Train & Test"
      ]
    },
    {
      "metadata": {
        "id": "mKdQChf1_d3Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will use sklearn to learn how to split our data into train and test using sklearn."
      ]
    },
    {
      "metadata": {
        "id": "12Jhw2NkLC3Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
        "\n",
        "print('We select randomly our train set containing '+str(X_train.shape[0])+' examples and our test set containing '+str(X_test.shape[0])+' examples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lhA3_WkCMJE3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log_reg = LogisticRegression(solver='lbfgs', random_state=123)\n",
        "\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "y_predict_training = log_reg.predict_proba(X_train)[:, 1]\n",
        "y_predict_testing = log_reg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "fpr_train, tpr_train, _ = roc_curve(y_train, y_predict_training)\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, y_predict_testing)\n",
        "\n",
        "plt.plot(fpr_train, tpr_train, color='orange', label='Training set')\n",
        "plt.plot(fpr_test, tpr_test, color='blue', label='Testing set')\n",
        "plt.xlabel('False positive rate (1-specificity)')\n",
        "plt.ylabel('True positive rate (sensitivity)')\n",
        "plt.title('ROC Curve', fontsize=17)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "df1yH_Q4Msko",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auc_train = roc_auc_score(y_train, y_predict_training)\n",
        "auc_test = roc_auc_score(y_test, y_predict_testing)\n",
        "\n",
        "\n",
        "print('AUC for trainning set: '+str(auc_train))\n",
        "print('AUC for testing set: '+str(auc_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wy0sLLRcN74X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can see that the model perform less well on the testing than the training set. \n",
        "\n",
        "The performance of the model in the testing set is the one you should care the most. "
      ]
    },
    {
      "metadata": {
        "id": "HuAlUVJuOa4b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cross validation"
      ]
    },
    {
      "metadata": {
        "id": "_WDo47XeOdkv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To be sure that your model perform well and not just on one set of your set your should use cross validation.\n",
        "\n",
        "Kfold will iterate your previous split train test radomly K times."
      ]
    },
    {
      "metadata": {
        "id": "p0nf2OiROnMz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "log_reg = LogisticRegression(solver='lbfgs', random_state=123)\n",
        "\n",
        "crossval_scores = cross_val_score(log_reg, X, Y, scoring='roc_auc', cv=10)\n",
        "\n",
        "print(crossval_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ehfqodmVRYLg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see our AUC for the different folder we randomly created. "
      ]
    },
    {
      "metadata": {
        "id": "V3wpDuTCRUxi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auc_mean_CV = np.mean(crossval_scores)\n",
        "print('Thanks to cross validation we can compute a more stable AUC: '+str(auc_mean_CV))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4uOIYIQgSC8e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5 GridSearch"
      ]
    },
    {
      "metadata": {
        "id": "ZP_cidvDSGe1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Grid search is an algorithm that can help you to tune your model. \n",
        "\n",
        "This algorithm will test for you to train model with different hyperparameters and will keep the one that give the best performances."
      ]
    },
    {
      "metadata": {
        "id": "lpSHPmrCQBQm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "log_reg = LogisticRegression(solver='lbfgs', random_state=123)\n",
        "\n",
        "# Parameter we want to test\n",
        "parameters = {'C':[0.01, 0.05, 0.1, 0.5, 1, 5, 10, 15]}\n",
        "\n",
        "# Initialize our gridsearch\n",
        "grid = GridSearchCV(log_reg, parameters, cv=10)\n",
        "\n",
        "# Test all possiblity and keep the best one\n",
        "model = grid.fit(X, Y)\n",
        "\n",
        "# Return the best parameter tested\n",
        "print('The best tested parameter is : '+str(model.best_params_))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}